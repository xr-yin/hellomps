"""This module demonstrates the Frobenius norm errors in our LPTN simulations converge quadratically with time step size O(dt^2) in 
the presence of Strang splitting. 

The first two models we study are the edge-driving Heisenberg XXZ chain and the dissipative-driven Bose Hubburd chain. The former have 
only non-trivial Krauss dimension at the first and last site of the chain, as a result of having local dissipators only at the two edges. 
The latter, on the other hand, have local dissipator acting on every site. They both show that the Frobenius norm errors produced by our
tensor network approach converge in the second order of time step.

In addition, we simulate a transverse ising model without any quantum channels to show the algorithm reduces to TEBD2. For completion, we
also simulate a toy model with random dissipators and trivial coherent dynamics to study the errors generated by the dissipative layer alone.
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.sparse.linalg import expm_multiply

import os
import sys
import time
import logging
from copy import deepcopy
logging.basicConfig(level=logging.WARNING)

hellompspath = os.path.dirname(os.path.abspath(os.getcwd()))
sys.path.append(os.path.join(hellompspath, "hellomps"))

from hellomps.networks.lptn import LPTN
from hellomps.networks.mps import MPS
from hellomps.models.spin_chains import TransverseIsing, Heisenberg, dissipative_testmodel
from hellomps.models.boson_chains import DDBoseHubburd
from hellomps.algorithms.lindblad_master import LindbladOneSite

def XXZ(N: int, tmax: float, dt_list: list, ax1: plt.Axes, ax2: plt.Axes):
    """we use the Heisenberg XXZ model to test if our simulation method exhibit quadratic errors

    Parameters
    ----------
    N : int
        system size
    tmax : float
        total time for simulation
    dt_list : list
        list of time steps
    ax1 : matplotlib.pyplot.Axes object
        the error plot
    ax2 : matplotlib.pyplot.Axes object
        the runtime plot

    Remarks
    ----------
    The full Liouvillian matrix has a size of n^2 x n^2, which requires a lot of computer memory if 
    system size is large, which is why we need tensor network methods for simulation.
    The quadratic error scaling can be violated if the bond dimensions are chosen too small due to the
    accumulated dicard of weights. Therefore, it is worthwhile to pick the parameters (bond dimensions, 
    time step) to balance the trotter errors and the discarded weights.
    """

    X = LPTN.gen_polarized_spin_chain(N, '+x')

    err_t = np.zeros(len(dt_list))
    time_t = np.zeros(len(dt_list))
    model = Heisenberg(N, (1., 1., 1.5), 0., 1.)

    Xt_ref = expm_multiply(tmax * model.Liouvillian, X.to_density_matrix().ravel())

    for bd,kd in [(10,10), (15,15), (15,20), (20,15), (20,20)]:
        for n, dt in enumerate(dt_list):
            psi = deepcopy(X)
            lab = LindbladOneSite(psi, model)
            Nsteps = round(tmax / dt)
            print(f"Nsteps={Nsteps}")
            start = time.time()
            lab.run_detach(Nsteps, dt, 1e-9, bd, kd, max_sweeps=2)
            time_t[n] = time.time() - start
            # record error
            err_t[n] = np.linalg.norm(psi.to_density_matrix().ravel() - Xt_ref)
            print('trace:', np.trace(psi.to_density_matrix()))

        print('errors:', err_t)
        ax1.loglog(dt_list, err_t, 'o-', label=f'bd={bd},kd={kd}')
        ax2.plot(dt_list, time_t, 'x-', label=f'bd={bd},kd={kd}')

    ax1.plot(dt_list, np.array(dt_list)**2, '--', label="$\delta t^2$") # second order in dt
    ax1.set_xlabel("$\delta t$")
    ax1.set_ylabel("errors")
    ax1.set_title(f'XXZ model simulation up to t={tmax}')

    ax2.set_ylabel("execution times (s)")
    ax2.set_yscale('log')

    ax1.legend()
    ax2.legend()

def BoseHubbardRun(N: int, d: int, tmax: float, dt_list: list, ax1: plt.Axes, ax2: plt.Axes):
    """we use the dissipative Bose Hubburd model to test if our simulation method exhibit quadratic errors

    Parameters
    ----------
    N : int
        system size
    tmax : float
        total time for simulation
    dt_list : list
        list of time steps
    ax1 : matplotlib.pyplot.Axes object
        the error plot
    ax2 : matplotlib.pyplot.Axes object
        the runtime plot
    """
    # initiate a vaccum state
    A = np.zeros([1,1,d,1])
    A[0,0,0,0] = 1.
    X = LPTN([A]*N)
    print('trace at t=0:', np.trace(X.to_density_matrix()))

    err_t = np.zeros(len(dt_list))
    time_t = np.zeros(len(dt_list))
    model = DDBoseHubburd(N, d, t=1., U=1., mu=0.5, F=1., gamma=0.2)

    Xt_ref = expm_multiply(tmax * model.Liouvillian, X.to_density_matrix().ravel())

    for bd,kd in [(5,5), (5,10), (10,5), (10,10)]:
        for n, dt in enumerate(dt_list):
            psi = deepcopy(X)
            lab = LindbladOneSite(psi, model)
            Nsteps = round(tmax / dt)
            print(f"Nsteps={Nsteps}")
            start = time.time()
            lab.run_detach(Nsteps, dt, 1e-9, bd, kd, max_sweeps=2)
            time_t[n] = time.time() - start
            # record error
            err_t[n] = np.linalg.norm(psi.to_density_matrix().ravel() - Xt_ref)
            logging.info(f'trace={np.real_if_close(np.trace(psi.to_density_matrix()))}')

        print(f'bd_max={bd}, kd_max={kd}')
        print('errors:', err_t)
        ax1.loglog(dt_list, err_t, 'o-', label=f'bd={bd},kd={kd}')
        ax2.plot(dt_list, time_t, 'x-', label=f'bd={bd},kd={kd}')

    ax1.plot(dt_list, np.array(dt_list)**2, '--', label="$\delta t^2$") # second order in dt
    ax1.set_xlabel("$\delta t$")
    ax1.set_ylabel("errors")
    ax1.set_title(f'Bose Hubbard simulation up to t={tmax}')

    ax2.set_ylabel("execution times (s)")
    ax2.set_yscale('log')

    ax1.legend()
    ax2.legend()

def tfi_coherent():
    """errors from the coherent layer alone
    the LindbladOneSite() will reduce to a second order TEBD in absense of dissipators"""

    N = 12
    tmax = 2.

    dt_list = np.array([0.5**k for k in range(6)])  # hence the total time steps = 2**k
    err_t = np.zeros(len(dt_list))

    model = TransverseIsing(N, g=1.5)

    v = MPS.gen_polarized_spin_chain(N, '+z')
    # reference time-evolved state
    vt_ref = expm_multiply(-1j * tmax * model.H_full, v.as_array())
    rhot_ref = np.outer(vt_ref, vt_ref.conj())

    for n, dt in enumerate(dt_list):

        psi = LPTN.gen_polarized_spin_chain(N, '+z')
        lab = LindbladOneSite(psi, model)

        Nsteps = round(tmax / dt)
        logging.info(f"Nsteps={Nsteps}")

        lab.run_detach(1, dt, tol=1e-9, m_max=25, k_max=5, max_sweeps=2)
        lab.run_detach(Nsteps-1, dt, tol=1e-9, m_max=25, k_max=5, max_sweeps=1)
        print(psi.bond_dims)
        print(psi.krauss_dims)

        # record error
        err_t[n] = np.linalg.norm(psi.to_density_matrix() - rhot_ref)

    print(err_t)
    plt.loglog(dt_list, err_t, 'o-', label='variational')
    plt.loglog(dt_list, dt_list**2, '--', label="$\delta t^2$") # second order in dt
    plt.xlabel('$\delta t$')
    plt.ylabel('errors')
    plt.legend()

    plt.savefig('tfi_coherent')
    
def dissipative_dynamics():
    """errors from the dissipative layer alone

    Since no two-qubit gates from the unitary time evolution are present, the bond 
    dimensions stay strictly the same. The SVD along the Kraus bond is truncation-free, 
    so long as the k_max is greater than mL*d*mR. This is easy to satisfy if we start 
    with a product state, in this case, the error should be close to the machine error.
    """
    
    N = 7
    tmax = 1.

    dt_list = np.array([0.5**k for k in range(5)])  # hence the total time steps = 2**k
    err_t = np.zeros(len(dt_list))

    model = dissipative_testmodel(N)

    x = LPTN.gen_random_state(N, m_max=10, k_max=10, phy_dims=[2]*N)
    x.orthonormalize('right')
    x.orthonormalize('left')
    print('bond dimensions at start:', x.bond_dims)
    print('Kraus dimensions at start:', x.krauss_dims)
    # reference time-evolved state
    xt_ref = expm_multiply(tmax * model.Liouvillian(model.H_full, *model.L_full), x.to_density_matrix().ravel())

    for n, dt in enumerate(dt_list):

        psi = deepcopy(x)
        lab = LindbladOneSite(psi, model)

        Nsteps = round(tmax / dt)
        logging.info(f"Nsteps={Nsteps}")

        lab.run_detach(1, dt, tol=1e-9, m_max=15, k_max=15, max_sweeps=2)
        lab.run_detach(Nsteps-1, dt, tol=1e-9, m_max=15, k_max=15, max_sweeps=1)

        print('bond dimensions at finish:', psi.bond_dims)
        print('Kraus dimensions at finish:', psi.krauss_dims)

        # record error
        err_t[n] = np.linalg.norm(psi.to_density_matrix().ravel() - xt_ref)

    print(err_t)
    plt.loglog(dt_list, err_t, 'o-', label='variational')
    plt.xlabel('$\delta t$')
    plt.ylabel('errors')
    plt.legend()
    plt.tight_layout()
    plt.savefig('random_dissipative')

if __name__ == '__main__': 

    tmax = float(input('simulation time:') or 1.)
    num_intervals = int(input('number of time intervals:') or 4)

    # the total time steps = 2**k
    dt_list = np.array([0.5**k for k in range(num_intervals+1)])

    # convergence plots
    fig, (ax1,ax2) = plt.subplots(2,2)
    fig.set_size_inches(12,16)
    fig.suptitle('Strang splitting of Liouville operator')

    XXZ(8, tmax, dt_list, ax1[0], ax1[1])
    BoseHubbardRun(6, 3, tmax, dt_list, ax2[0], ax2[1])

    plt.savefig('LPTN_converge')
    plt.show()